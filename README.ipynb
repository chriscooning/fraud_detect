{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "[1. Motivation](#motive)<br> \n",
    "[2. Data](#data)\n",
    ">   [i. Pipeline](#pipeline)<br>\n",
    "    [ii. Intro to Fraud](#intro)<br>\n",
    "    [iii. Unbalanced Datasets](#unbalanced)<br>\n",
    "    \n",
    "[3. Machine Learning Classification Models](#mlclass)\n",
    "> [i. Undersampling](#undersample)<br>\n",
    "> [ii. SMOTE](#smote)<br>\n",
    "> [iii. Isolation Forest](#isolation)<br>\n",
    "> [iv. Auto-encoder](#auto)<br>\n",
    "> [v. Best Model](#best)<br>\n",
    "\n",
    "[4. Conclusion](#conclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "<a id=\"motive\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "<a id=\"data\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss that PCA had already been performed on all but 2 of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "<a id=\"pipeline\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to Fraud\n",
    "<a id=\"intro\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbalanced Datasets\n",
    "<a id=\"unbalanced\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced data in terms of a classification models means that there is proportionally more of one class (taget) than the other. This is an issue because what happens during training and deployment of machine learning classifiers is  that there are not enough examples of the minority class for a model to effectively learn the \"decision boundary\".\n",
    "\n",
    "All models will struggle on new or true testing data as they just didn't have enough evidence and \"coaching\" to learn the difference!\n",
    "\n",
    "There are two ways to attempt to solve this issue:\n",
    "\n",
    "1. Undersampling\n",
    "2. Oversampling\n",
    "\n",
    "Undersampling\n",
    "\n",
    "We find out how many instances are in the minority class,  fraudulent transactions in this case.\n",
    "Then we need to make a new data set that is a randomized (shuffled) subsample of the majority class, normal transactions, to the same amount as fraud transactions. This creates an even, balanced data set of 50% of each class (for binary classification such as fraud vs not fraud.\n",
    "\n",
    "For this dataset that means we limit our original dataset to be 492 cases of fraud and 492 cases of normal transactions.\n",
    "\n",
    "\n",
    "Warning: This methodology of undersampling comes at a relatively large price. The original data set was approximately 284,000 transactions, and now it has been reduced to 984.\n",
    "\n",
    "There is a risk that a classification model will not perform well since there is large volumes of general information loss.\n",
    "\n",
    "One way to solve this information loss issue brings us to our other option:\n",
    "\n",
    "Oversampling\n",
    "\n",
    "You want to oversample instances the minority class. \n",
    "\n",
    "How do we oversample something that doesn't exist? \n",
    "\n",
    "a. Make copies of exact samples from the minority class in the training dataset prior to fitting a model. Rather simplistic and doesn't actually assist in information gain like actual new data would provide.\n",
    "\n",
    "b. Synthesize new instances from the minority class. This methodology is called Synthetic Minority Oversampling TEchnique, or SMOTE for short. This technique was described by Nitesh Chawla, et al. in their 2002 paper named for the technique titled “SMOTE: Synthetic Minority Over-sampling Technique.”\n",
    "\n",
    "SMOTE will be discussed further below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss not removing outliers UPDATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Classification Models\n",
    "<a id=\"mlclass\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling\n",
    "<a id=\"undersample\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE\n",
    "<a id=\"smote\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This oversampling technique ultimately selects instances that are close to each other in the existing dataset's feature space. It then \"draws\" a line between the instances selected and adds new sample at a point somwhere along that line.\n",
    "\n",
    "To put this into a perspective we can digest using machine learning methods and terms:\n",
    "\n",
    "Step 1) a random instance from the minority class is first chosen.\n",
    "Step 2) k of the nearest neighbors for that example are found (typically k=5).\n",
    "Step 3) a randomly selected \"neighbor\" is chosen.\n",
    "Step 4) finally, a synthetic example is created at a randomly selected point between the two examples in feature space.\n",
    "\n",
    "That is a lot of randoms!\n",
    "\n",
    "Why does this work? Well, \"new synthetic\" instances from the minority class that are generated through this process  are generally speaking close in feature space to existing examples from the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain what is isolation forest \n",
    "explain model's strength regarding how gridsearching parameters is best performed on the contamination score.\n",
    "explain why you want to have a contamination score higher generally than your actual % of anomaly\n",
    "\n",
    "explain why you want high recall\n",
    "\n",
    "Show confusion matrix for best performing grid searched parameters here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model\n",
    "<a id=\"best\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ [placeholder for best model confusion matrix]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
