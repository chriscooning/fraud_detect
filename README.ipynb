{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"1360\" height=\"900\" src=\"images/fraud-header.png\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jessica Mouras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [slides](https://docs.google.com/presentation/d/1NIVcXFh3zVNhOd-Oj9b31W8xFNyU4elONy9d2AVSvns/edit?usp=sharing) **|** [github](https://github.com/jessicapmouras/fraud_detect) **|** [linkedin](https://www.linkedin.com/in/jessicamouras/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "[1. Motivation](#motive)<br> \n",
    "[2. Data](#data)\n",
    ">   [i. Pipeline](#pipeline)<br>\n",
    "    [ii. Intro to Fraud](#intro)<br>\n",
    "    [iii. Unbalanced Datasets](#unbalanced)<br>\n",
    "    \n",
    "[3. Methods](#mlclass)<br>\n",
    "> [i. Undersampling](#undersample)<br>\n",
    "> [ii. SMOTE](#smote)<br>\n",
    "\n",
    "[4. Anomaly Detection Techniques](#technique)<br>\n",
    "> [i. Isolation Forest](#isolation)<br>\n",
    "> [ii. PCA Anomaly Detection](#pca)<br>\n",
    "> [iii. Neural Network Autoencoder](#auto)<br>\n",
    "\n",
    "[5. Conclusion & Further Application](#conclude)<br>\n",
    "> [i. References](#references)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "<a id=\"motive\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started my career in financial services As a CPA (license still current, but inactive) who found the gritter aspects of accounting and finance most intriguing. In fact, my first consulting project ever was an Anti Money Laundering (AML) assignment that deployed Machine Learning techniques, but was 2012 and I was a very junior employee. \n",
    "\n",
    "I wanted to revisit the topic of money laundering by building methods and models to assist with identifying fraudulent transactions.\n",
    "\n",
    "Here, I assess a large dataset of credit card transactions over 2 days in September 2013 of European cardholders to classify the transactions between fraud and non-fraud. As discussed below, by doing this classification, I am detecting anomalies. Through my analysis, I hope to determine which methods are best for detecting fraudlent transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "<a id=\"data\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed briefly above, this dataset contains transactions made by European credit holders cards in September 2013 over the coure of two days. The minority class is  492 frauds out of 284,807 transactions which is 0.172% of all transactions. Therefore, the majority class is 99.827% of transactions.\n",
    "\n",
    "The following had already been done to the data to anonymize the information except for time and amount:\n",
    "\n",
    "+ PCA Transformation:  the features went through a PCA transformation (Dimensionality Reduction technique) which creates latent features that are some combination of the original features of the data. \n",
    "\n",
    "+ Scaling: The data has already been scaled as in order to perform PCA, one must scale the features prior to transformation.\n",
    "\n",
    "I separately scaled time and amount to perform the remainder of this analysis.\n",
    "\n",
    "Due to the anonymization process, the feature names, descriptions, and nature is largely undisclosed. I reviewed the features for data-leakage and potential rank issues (where a feature is a transformation of another feature and therefore redundant). Note: during the EDA process, I did not choose to select outliers to remove, as they could be possible important transactions to review during the anomaly classification process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "<a id=\"pipeline\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform my analysis I used the following libaries:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"460\" height=\"200\" src=\"images/keras_regression_logos.png\">\n",
    "</p>\n",
    "\n",
    "\n",
    "The data was already classified as 1 - the class for fraudulent transaction and 0 - the class for normal transactions. Throughout this analysis I will refer to predicting a fraud instance correctly to be considered a true positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Fraud\n",
    "<a id=\"intro\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many types of financial fraud and many subsets of Money Laundering. In the course of this notebook, we will only be addressing the concept of Money Laundering through a Retail Banking Institution. Also known as: Credit Card Fraud.\n",
    "\n",
    ">*Credit card fraud is the unauthorized use of a credit or debit card, or similar payment tool (ACH, EFT, recurring charge, etc.), to fraudulently obtain money or property.* - **Federal Bureau of Investigation**\n",
    "\n",
    "Disclaimer: the methods deployed in this notebook may not be applicable or appropriate for other types of Money Laundering e.g. through an Investment Bank / Private Equity Fund, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbalanced Datasets\n",
    "<a id=\"unbalanced\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced data in terms of a classification models means that there is proportionally more of one class (taget) than the other. This is an issue because what happens during training and deployment of machine learning classifiers is  that there are not enough examples of the minority class for a model to effectively learn the \"decision boundary\".\n",
    "\n",
    "All models will struggle on new or true testing data as they just didn't have enough evidence and \"coaching\" to learn the difference!\n",
    "\n",
    "There are two ways to attempt to solve this issue:\n",
    "\n",
    "1. Undersampling\n",
    "2. Oversampling\n",
    "3. Other Techniques: Anomaly Detection\n",
    "\n",
    "**Undersampling**\n",
    "\n",
    "We find out how many instances are in the minority class,  fraudulent transactions in this case.\n",
    "Then we need to make a new data set that is a randomized (shuffled) subsample of the majority class, normal transactions, to the same amount as fraud transactions. This creates an even, balanced data set of 50% of each class (for binary classification such as fraud vs not fraud. For this dataset that means we limit our original dataset to be 492 cases of fraud and 492 cases of normal transactions.\n",
    "\n",
    "Warning: This methodology of undersampling comes at a relatively large price. The original data set was approximately 284,000 transactions, and now it has been reduced to 984.There is a risk that a classification model will not perform well since there is large volumes of general information loss.\n",
    "\n",
    "One way to solve this information loss issue brings us to our other option:\n",
    "\n",
    "**Oversampling**\n",
    "\n",
    "You want to oversample instances the minority class. How do we oversample something that doesn't exist? \n",
    "\n",
    "**a.** Make copies of exact samples from the minority class in the training dataset prior to fitting a model. Rather simplistic and doesn't actually assist in information gain like actual new data would provide.\n",
    "\n",
    "**b.** Synthesize new instances from the minority class. This methodology is called Synthetic Minority Oversampling TEchnique, or SMOTE for short. This technique was described by Nitesh Chawla, et al. in their 2002 paper named for the technique titled “SMOTE: Synthetic Minority Over-sampling Technique.”\n",
    "\n",
    "**Anomaly Detection Techniques**\n",
    "\n",
    "*Isolation Forest*: A random tree based ensemble method that works to isolate anomaly values through a supervised or unsupervised classifier. Anomalies are the ponts with the shortest average path length. There is no profiling of normal instances nor is there any point based calculations.\n",
    "\n",
    "*Auto-encoders*: A form of unsupervised learning where we measure how “far” the reconstructed data point provived by the model is from the actual, original datapoint. If the error is large, then the original datapoint is likely an anomaly. Here we used 2 methods to create autoencoders:\n",
    "+ an unsupervised PCA transformation that transforms the feature space data via linear compression and reconstruction.\n",
    "+ an unsupervised neural network that transforms the data via nonlinear compression and reconstruction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "<a id=\"mlclass\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methods addressed during this analysis are as follows:\n",
    "\n",
    "**Undersampling and Machine Learning Classification Models:**\n",
    "+ Logistic Regression\n",
    "+ kNN Classifier\n",
    "+ Decision Trees Classifier\n",
    "+ Random Forest Classifier\n",
    "+ Gradient Boosted Classifier\n",
    "\n",
    "**Oversampling:**\n",
    "+ Discussion of Synthetic minority over-sampling technique (SMOTE)\n",
    "\n",
    "**Anomaly Detection for Unbalanced Classes:**\n",
    "+ Isolation Forest\n",
    "+ PCA Anomaly Detection\n",
    "+ Neural Network Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling\n",
    "<a id=\"undersample\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To undersample and create balanced classes within my dataset. I had to reduce my original data to double the amount of the minority class. As there were 492 fraud transactions, I shuffled the remainder of the data and selected 492 random non-fraud transactions. In total, the undersampled dataset size is now 984 transactions. The information lost from the original transaction is 99.7%. Not good at all. That is a signifcant amount of loss just to create an inital data population. I decided to not remove any of the features and continue with standardized data as described above.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"260\" height=\"100\" src=\"images/undersample_sciz.png\">\n",
    "</p>\n",
    "\n",
    "Despite all of the information loss and troubling aspects of undersampling in this manner, I wanted to see what sort of results I would achieve with classification on this reduced data. Ultimately, I wanted to see if the evaluated models during undersampling serve either oversampled or original data in future analysis.\n",
    "\n",
    "I evaluated the following models on the undersampled data:\n",
    "\n",
    "+ Logistic Regression\n",
    "+ kNN Classifier\n",
    "+ Decision Trees Classifier\n",
    "+ Random Forest Classifier\n",
    "+ Gradient Boosted Classifier\n",
    "\n",
    "As shown here by the ROC Curve below, the models' performance on cross validated undersampled data was quite good. The best performing models were Logistic Regression and Gradient Boosted Classifier. I chose these to deploy on the original dataset testing population to evaluate performance of a model trained on a balanced, but severely undersampled subsample.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"460\" height=\"200\" src=\"images/undersamp_full_viz.png\">\n",
    "</p>\n",
    "\n",
    "As I am looking to perform a binary classification, my most important metrics to evalute are:\n",
    "+ Precision: is the fraction of correct positives (in this case fraud instances) among the total predicted positives. It is also called the accuracy of positive predictions. \n",
    "\n",
    "+ Recall: is the fraction of correct positives among the total positives in the dataset. It is indicating how many total positives of the actual dataset were covered(classified correctly) while doing prediction.\n",
    "\n",
    "The [precision - recall tradeoff](https://www.machinelearningaptitude.com/topics/machine-learning/what-is-precision-recall-tradeoff/) strategy depends on the practical application assessed. A binary classifier will always miss classify some datapoints if provided enough information/ data over time. The incorrect classification rate is either compromising the precision or recall scores.\n",
    "\n",
    "In the case of this assessment of fraud detection. Recall is more important than precision, as you would like to have less False Negatives (fraud instances labeled normal transactions and therefore missed anomalies) in trade off to have less False Positives (normal instances labeled as fraud).\n",
    "\n",
    "\n",
    "Meaning, getting a False Negative (missing a fraudulent transaction) is very costly:\n",
    "+ Financial loss (actual fraud amount, insurance premiums/coverage, losing customers to competitor with better security)\n",
    "+ Reputation loss (Wachovia bank is a good example of a tarnished reputation and ultimate demise)\n",
    "\n",
    "And conversely, a False Positive (spending some time investigating a normal transaction) is not as costly:\n",
    "+ Salary rate of individual investigating the transaction\n",
    "+ Some customer interaction for a false alarm, small customer frustration\n",
    "\n",
    "Deploying the best performing classification models on the original dataset, the results display why this method isn't sufficient for detecting fraud.\n",
    "\n",
    "While the accuracy scores are quite high, upon further assessment it appears that the models are just predicting the majority class, but ultimately are failing to catch the fraud instances.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"460\" height=\"200\" src=\"images/undersample_roc2.png\">\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"460\" height=\"200\" src=\"images/undersample_logistic_pr.png\">\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"460\" height=\"200\" src=\"images/undersample_gradient_pr.png\">\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling (SMOTE)\n",
    "<a id=\"smote\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthetic minority over-sampling technique (SMOTE) is an oversampling technique that selects instances close to each other in the existing dataset's feature space. It then \"draws\" a line between the instances selected and adds new sample at a point somwhere along that line.\n",
    "\n",
    "To put this into a perspective we can digest using machine learning methods and terms to define the steps:\n",
    "\n",
    "Step 1) a random instance from the minority class is first chosen.\n",
    "Step 2) k of the nearest neighbors for that example are found (typically k=5).\n",
    "Step 3) a randomly selected \"neighbor\" is chosen.\n",
    "Step 4) finally, a synthetic example is created at a randomly selected point between the two examples in feature space.\n",
    "\n",
    "That is a lot of randoms!\n",
    "\n",
    "Why does this work? Well, \"new synthetic\" instances from the minority class that are generated through this process  are generally speaking close in feature space to existing examples from the minority class.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"460\" height=\"200\" src=\"images/SMOTE_viz.png\">\n",
    "</p>\n",
    "\n",
    "**WARNING:** This technique must be executed correctly to retain the original integrity of the class distribution of the original dataset. This process must be peforming during, **not** before the cross validation process. \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"460\" height=\"200\" src=\"images/smote-cross1.png\">\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"460\" height=\"200\" src=\"images/smote-cross2.png\">\n",
    "</p>\n",
    "\n",
    "This is not a very good idea for data with many features. The larger the dimension space, the more complex it is for kNN to collect nearest neighbors. With 30 features, this approach was becoming tedious. I would have a hard time justifying synthetic samples for severely unbalanced classed when there are other machine learning techniques that are better suited to the actual problem at hand -- anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection Techniques\n",
    "<a id=\"techniques\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest\n",
    "<a id=\"isolaiton\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain what is isolation forest \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"460\" height=\"200\" src=\"images/iso_viz.png\">\n",
    "</p>\n",
    "\n",
    "explain model's strength regarding how gridsearching parameters is best performed on the contamination score.\n",
    "explain why you want to have a contamination score higher generally than your actual % of anomaly\n",
    "\n",
    "explain why you want high recall\n",
    "\n",
    "Show confusion matrix for best performing grid searched parameters here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Anomaly Detection\n",
    "<a id=\"pca\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss that this is linear decompression\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"460\" height=\"200\" src=\"images/PCA-viz.png\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Autoencoding\n",
    "<a id=\"auto\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ describe and discuss autoencoding\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"460\" height=\"200\" src=\"images/nn-autoencoder-ref.png\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion & Future Application\n",
    "<a id=\"conclude\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ [placeholder for conclusion]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "<a id=\"references\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **[1]** FBI.gov, Scams and Safety, Common Scams and Crimes, 2019.\n",
    "+ **[2]**  V. Chandola and V. Kumar, Outlier and Anomaly Detection Anomaly Detection: A Survey, ACM Computing Surveys, 2009.\n",
    "+ **[3]** J. Brownlee, SMOTE for Imbalanced Classification with Python, Imbalanced Classification, January 2020.\n",
    "+ **[4]**  E. Sharova, Unsupervised Anomaly Detection with Isolation Forest, PyData London Conference 2018.\n",
    "+ **[5]**  A. A. Patel, Hands-On Unsupervised Learning Using Python, February 2019.\n",
    "+ **[6]** C. Medford, Generative-Neural-Networks, February 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "328.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
