{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "[1. Motivation](#motive)<br> \n",
    "[2. Data](#data)\n",
    ">   [i. Pipeline](#pipeline)<br>\n",
    "    [ii. Intro to Fraud](#intro)<br>\n",
    "    [iii. Unbalanced Datasets](#unbalanced)<br>\n",
    "    \n",
    "[3. Machine Learning Classification Models](#mlclass)\n",
    "> [i. Undersampling](#undersample)<br>\n",
    "> [ii. SMOTE](#smote)<br>\n",
    "> [iii. Isolation Forest](#isolation)<br>\n",
    "> [iv. Auto-encoder](#auto)<br>\n",
    "> [v. Best Model](#best)<br>\n",
    "\n",
    "[4. Conclusion](#conclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "<a id=\"motive\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started my career in financial services. As a CPA (license still current, but inactive) who found the gritter aspects of accounting and finance most intriguing.\n",
    "In fact, my first consulting project ever was an Anti Money Laundering (AML) assignment that has now since been de-classified, but was something that I only got to see as a junior employee. \n",
    "\n",
    "I wanted to revisit the topic of money laundering by building methods and models to assist with identifying fraudulent transactions.\n",
    "\n",
    "I am going to assess a large financial dataset of credit card transaction to classify instances, detect anomalies, and determine which methods are best for the data discussed below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "<a id=\"data\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains transactions made by European credit holders cards in September 2013 over the coure of two days.\n",
    "\n",
    "This data is highly unbalanced in terms of classification.\n",
    "The minority class is  492 frauds out of 284,807 transactions which is 0.172% of all transactions.\n",
    "\n",
    "Therefore, the majority class is 99.827% of transactions.\n",
    "\n",
    "The following had already been done to the data to anonymize the information except for time and amount:\n",
    "\n",
    "PCA Transformation:  the features went through a PCA transformation (Dimensionality Reduction technique) which creates latent features that are some combination of the original features of the data. \n",
    "\n",
    "Scaling: The data has already been scaled as in order to perform PCA, one must scale the features prior to transformation.\n",
    "\n",
    "I separately scaled time and amount to perform the remainder of this analysis.\n",
    "\n",
    "Now we will use various predictive models to see how accurate they are in detecting whether a transaction is a normal payment or a fraud. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "<a id=\"pipeline\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used pandas dataframes, sklearn, imblearn, --keras / tensorflow-- and proceeded to do all my calculations and tests after.  \n",
    "\n",
    "The data was already classified as 1 - the class for fraudulent transaction and 0 - the class for normal transactions. Thus, predicting a fraud instance correctly would be considered a true positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to Fraud\n",
    "<a id=\"intro\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many types of financial fraud and many subsets of Money Laundering (ML). In the course of this notebook, we will only be addressing the concept of Money Laundering through a Retail Banking Institution. Also known as: Credit Card Fraud.\n",
    "\n",
    "Disclaimer: the methods deployed in this notebook may not be applicable or appropriate for other types of Money Laundering e.g. through an Investment Bank / Private Equity Fund, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbalanced Datasets\n",
    "<a id=\"unbalanced\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced data in terms of a classification models means that there is proportionally more of one class (taget) than the other. This is an issue because what happens during training and deployment of machine learning classifiers is  that there are not enough examples of the minority class for a model to effectively learn the \"decision boundary\".\n",
    "\n",
    "All models will struggle on new or true testing data as they just didn't have enough evidence and \"coaching\" to learn the difference!\n",
    "\n",
    "There are two ways to attempt to solve this issue:\n",
    "\n",
    "1. Undersampling\n",
    "2. Oversampling\n",
    "3. Other Techniques: Anomaly Detection\n",
    "\n",
    "Undersampling\n",
    "\n",
    "We find out how many instances are in the minority class,  fraudulent transactions in this case.\n",
    "Then we need to make a new data set that is a randomized (shuffled) subsample of the majority class, normal transactions, to the same amount as fraud transactions. This creates an even, balanced data set of 50% of each class (for binary classification such as fraud vs not fraud.\n",
    "\n",
    "For this dataset that means we limit our original dataset to be 492 cases of fraud and 492 cases of normal transactions.\n",
    "\n",
    "Warning: This methodology of undersampling comes at a relatively large price. The original data set was approximately 284,000 transactions, and now it has been reduced to 984.\n",
    "\n",
    "There is a risk that a classification model will not perform well since there is large volumes of general information loss.\n",
    "\n",
    "One way to solve this information loss issue brings us to our other option:\n",
    "\n",
    "Oversampling\n",
    "\n",
    "You want to oversample instances the minority class. \n",
    "\n",
    "How do we oversample something that doesn't exist? \n",
    "\n",
    "a. Make copies of exact samples from the minority class in the training dataset prior to fitting a model. Rather simplistic and doesn't actually assist in information gain like actual new data would provide.\n",
    "\n",
    "b. Synthesize new instances from the minority class. This methodology is called Synthetic Minority Oversampling TEchnique, or SMOTE for short. This technique was described by Nitesh Chawla, et al. in their 2002 paper named for the technique titled “SMOTE: Synthetic Minority Over-sampling Technique.”\n",
    "\n",
    "Anomaly Detection Techniques\n",
    "\n",
    "Isolation Forest: isolate anomaly values through a supervised or unsupervised classifier. Anomalies are the ponts with the shortest average path length.\n",
    "\n",
    "\n",
    "Auto-encoders: detect anomaly values through an unsupervised neural network in which we measure how “far” the reconstructed data point provived by the model is from the actual, original datapoint. If the error is large, then the original datapoint is likely an anomaly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss not removing outliers UPDATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Classification Models\n",
    "<a id=\"mlclass\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling\n",
    "<a id=\"undersample\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE\n",
    "<a id=\"smote\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This oversampling technique ultimately selects instances that are close to each other in the existing dataset's feature space. It then \"draws\" a line between the instances selected and adds new sample at a point somwhere along that line.\n",
    "\n",
    "To put this into a perspective we can digest using machine learning methods and terms:\n",
    "\n",
    "Step 1) a random instance from the minority class is first chosen.\n",
    "Step 2) k of the nearest neighbors for that example are found (typically k=5).\n",
    "Step 3) a randomly selected \"neighbor\" is chosen.\n",
    "Step 4) finally, a synthetic example is created at a randomly selected point between the two examples in feature space.\n",
    "\n",
    "That is a lot of randoms!\n",
    "\n",
    "Why does this work? Well, \"new synthetic\" instances from the minority class that are generated through this process  are generally speaking close in feature space to existing examples from the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain what is isolation forest \n",
    "explain model's strength regarding how gridsearching parameters is best performed on the contamination score.\n",
    "explain why you want to have a contamination score higher generally than your actual % of anomaly\n",
    "\n",
    "explain why you want high recall\n",
    "\n",
    "Show confusion matrix for best performing grid searched parameters here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ describe and discuss autoencoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model\n",
    "<a id=\"best\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ [placeholder for best model confusion matrix]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
